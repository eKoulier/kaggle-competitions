{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da035fe58e548e8b1b7e8e89725b9e6bc745aa7b"
   },
   "source": [
    "# Humpback Whale Identification \n",
    "\n",
    "This kernel contains our first draft solution to the [kaggle competition](https://www.kaggle.com/c/humpback-whale-identification). A few things should be taken care so that the notebook can properly operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Keras Imports\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Remove Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2cea35de3530cc898be5b85063b84e875401d092"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all.zip', 'sample_submission.csv', 'Test', 'Train', 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "46a8839e13a14eb8d16ea6823de9927ea63d5001"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, we have 25361 training images that correspond to 5005 different classes\n",
      "The class that contains most pictures is 'new_whale', and 9664 observations belong to this class.\n",
      "2073 classes have only one observation.\n"
     ]
    }
   ],
   "source": [
    "print('In total, we have {} training images that correspond to {} different classes'\n",
    "      .format(len(train_df), len(train_df['Id'].unique())))\n",
    "\n",
    "print(\"The class that contains most pictures is '{}', and {} observations belong to this class.\"\n",
    "      .format(train_df.groupby('Id').size().idxmax(), train_df.groupby('Id').size().max()))\n",
    "\n",
    "print('{} classes have only one observation.'\n",
    "      .format(len(train_df.groupby('Id').count()[train_df.groupby('Id').count()['Image']==1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the dataset is very unbalanced since there are 5005 classes and 38.1% of the training images belong to the class called 'new_whale'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "f46b24dbba74f22833cac6140e60348b15a8e047"
   },
   "outputs": [],
   "source": [
    "def prepareImages(data, m, dataset):\n",
    "    # This function is inspired by this notebook: https://www.kaggle.com/pestipeti/keras-cnn-starter\n",
    "    # and it is slightly modified\n",
    "    \n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, 100, 100, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:\n",
    "        #load images into images of size 100x100x3\n",
    "        img = image.load_img(\"Data/\"+dataset+\"/\"+fig, target_size=(100, 100, 3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        X_train[count] = x\n",
    "        \n",
    "        # Estimate how much time is lesft\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "6587a101b58af064af0f9c60a1070c6c8f52d45f"
   },
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "4afe4128a0cd6859848c8a80686208082d647c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  0000e88ab.jpg\n",
      "Processing image:  501 ,  04c72257b.jpg\n",
      "Processing image:  1001 ,  09cacb84d.jpg\n",
      "Processing image:  1501 ,  0ef961892.jpg\n",
      "Processing image:  2001 ,  141b56a1a.jpg\n",
      "Processing image:  2501 ,  199a417aa.jpg\n",
      "Processing image:  3001 ,  1ec170983.jpg\n",
      "Processing image:  3501 ,  23f084b93.jpg\n",
      "Processing image:  4001 ,  29163ad0b.jpg\n",
      "Processing image:  4501 ,  2e0fab120.jpg\n",
      "Processing image:  5001 ,  3347515d9.jpg\n",
      "Processing image:  5501 ,  3842d71dc.jpg\n",
      "Processing image:  6001 ,  3d7f4c7d5.jpg\n",
      "Processing image:  6501 ,  425f763ca.jpg\n",
      "Processing image:  7001 ,  4714400cd.jpg\n",
      "Processing image:  7501 ,  4c082fbdf.jpg\n",
      "Processing image:  8001 ,  50c683e23.jpg\n",
      "Processing image:  8501 ,  560d986ad.jpg\n",
      "Processing image:  9001 ,  5b68c83ed.jpg\n",
      "Processing image:  9501 ,  60410f111.jpg\n",
      "Processing image:  10001 ,  654951f81.jpg\n",
      "Processing image:  10501 ,  6a572256c.jpg\n",
      "Processing image:  11001 ,  6f96f55b6.jpg\n",
      "Processing image:  11501 ,  74da2b511.jpg\n",
      "Processing image:  12001 ,  7989d9a27.jpg\n",
      "Processing image:  12501 ,  7e5aa2d8a.jpg\n",
      "Processing image:  13001 ,  832382cfb.jpg\n",
      "Processing image:  13501 ,  87f6c0a15.jpg\n",
      "Processing image:  14001 ,  8cfc22e5d.jpg\n",
      "Processing image:  14501 ,  91dcfedcd.jpg\n",
      "Processing image:  15001 ,  97079398e.jpg\n",
      "Processing image:  15501 ,  9c2ad64a9.jpg\n",
      "Processing image:  16001 ,  a11956dff.jpg\n",
      "Processing image:  16501 ,  a5f9ffe86.jpg\n",
      "Processing image:  17001 ,  aaf1a967b.jpg\n",
      "Processing image:  17501 ,  af9a1ffc6.jpg\n",
      "Processing image:  18001 ,  b4e02531d.jpg\n",
      "Processing image:  18501 ,  ba2355ca6.jpg\n",
      "Processing image:  19001 ,  bf60e7fed.jpg\n",
      "Processing image:  19501 ,  c49f39ce3.jpg\n",
      "Processing image:  20001 ,  c960111d0.jpg\n",
      "Processing image:  20501 ,  ce7984d8a.jpg\n",
      "Processing image:  21001 ,  d38efaec9.jpg\n",
      "Processing image:  21501 ,  d831d28ee.jpg\n",
      "Processing image:  22001 ,  dd3ca2387.jpg\n",
      "Processing image:  22501 ,  e288d66cf.jpg\n",
      "Processing image:  23001 ,  e7cc793db.jpg\n",
      "Processing image:  23501 ,  ec8c7229d.jpg\n",
      "Processing image:  24001 ,  f1b850552.jpg\n",
      "Processing image:  24501 ,  f6af8a4b8.jpg\n",
      "Processing image:  25001 ,  fc09f2302.jpg\n"
     ]
    }
   ],
   "source": [
    "X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "\n",
    "# Devide all images by the hisgest number of the pixel intensity.\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "675924f8863aef27cf90dc668e0a68cd609dfc1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y, label_encoder = prepare_labels(train_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "14d243b19023e830b636bea16679e13bc40deae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25361, 5005)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define our baseline model to check that everything works and that the submission can be done properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "e7af799d186a1b97b6aa325d7d576a1fb55a6c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv0 (Conv2D)               (None, 94, 94, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 94, 94, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 94, 94, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "avg_pool (AveragePooling2D)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "rl (Dense)                   (None, 500)               7200500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "sm (Dense)                   (None, 5005)              2507505   \n",
      "=================================================================\n",
      "Total params: 9,731,365\n",
      "Trainable params: 9,731,301\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This is a baseline model to check that everything works.\n",
    "# Improvements will be made in the future.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (7, 7), strides=(1, 1), name='conv0', input_shape=(100, 100, 3)))\n",
    "\n",
    "model.add(BatchNormalization(axis=3, name='bn0'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), name='max_pool'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1,1), name=\"conv1\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D((3, 3), name='avg_pool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\", name='rl'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Last layer's lenght should correpsond to the number of classes\n",
    "model.add(Dense(y.shape[1], activation='softmax', name='sm'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "169f45e150c3a584e0f655a8eda523e0675da63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  600/25361 [..............................] - ETA: 31:55 - loss: 7.3736 - acc: 0.3217"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=100, batch_size=100, verbose=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bca48a1d0963cbf70685b75431435cef9499895"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "debe961c93b72bef151d9aad3ca2cb500ee00aaa"
   },
   "outputs": [],
   "source": [
    "test = os.listdir(\"../Data/test/\")\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72ed8198f519f7b1ae3efbc688933c78d8cdd0e4"
   },
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52262195fc0b8755cff78bf8c98e6116d50f79af"
   },
   "outputs": [],
   "source": [
    "X_test = prepareImages(test_df, test_df.shape[0], \"test\")\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88c8d8ff98fbdb1df4218abb6bd51889e855a6fb"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np.array(X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66f0bdde31b8c7847916268aa82d9a1bdc9c0658"
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    \n",
    "    # The competition asks to provide five predictions per image\n",
    "    test_df.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09d7c1eb9b554e4e580b0c3c7eb609c15636892d"
   },
   "outputs": [],
   "source": [
    "test_df.head(10)\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
